{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "YlFBDzu-LL6v",
      "metadata": {
        "id": "YlFBDzu-LL6v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from math import ceil\n",
        "from torch.autograd import Function\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "649083dd",
      "metadata": {
        "id": "649083dd"
      },
      "outputs": [],
      "source": [
        "import triton\n",
        "import triton.language as tl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "hRyr14v0wSwN",
      "metadata": {
        "id": "hRyr14v0wSwN"
      },
      "outputs": [],
      "source": [
        "def naive_softmax(x:Tensor) -> Tensor:\n",
        "    max = x.max()\n",
        "    x -= x.max(dim = -1)[0][:, None] # this is done for numerical stability\n",
        "    num = torch.exp(x)\n",
        "    den = torch.sum(num, dim=1)[:, None]\n",
        "    return num / den\n",
        "\n",
        "# x = torch.rand(100, 200).to(DEVICE)\n",
        "# triton.testing.assert_close(naive_softmax(x), torch.nn.functional.softmax(x, dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9JmqnyDWw3i4",
      "metadata": {
        "id": "9JmqnyDWw3i4"
      },
      "outputs": [],
      "source": [
        "@triton.jit\n",
        "def fused_softmax_kernel(x_pointer, y_pointer, x_stride, y_stride, n_rows, n_cols, block_size: tl.constexpr):\n",
        "    # get the program id: each program of the grid handles one (or more) rows of the tensor\n",
        "    pid = tl.program_id(axis=0)\n",
        "\n",
        "    # strided execution: can run the program in a strided way (e.g. for row 0, 8, 16, ...)\n",
        "    row_step = tl.num_programs(axis=0) # n. of programs running on given axis\n",
        "\n",
        "    # loop through the rows executed by program with this pid\n",
        "    for row_idx in tl.range(pid, n_rows, row_step):\n",
        "        x_row_pointer = x_pointer + row_idx * x_stride\n",
        "\n",
        "        col_offset = tl.arange(0, block_size)\n",
        "        x_col_pointer = x_row_pointer + col_offset\n",
        "        mask = n_cols < block_size\n",
        "\n",
        "        # compute the softmax (with shift for numerical stab.)\n",
        "        row = tl.load(x_col_pointer, mask, other=-float('inf'))\n",
        "\n",
        "        max = tl.max(row, axis=0)\n",
        "        row_shift = row - max\n",
        "\n",
        "        num = tl.exp(row_shift)\n",
        "        den = tl.sum(num, axis=0)\n",
        "        y = num / den\n",
        "\n",
        "        y_row_pointer = y_pointer + row_idx * y_stride\n",
        "        y_col_offset = y_row_pointer + col_offset\n",
        "        tl.store(y_col_offset, y, mask)\n",
        "\n",
        "\n",
        "def fused_softmax_triton(x:Tensor, block_size:int=1024) -> Tensor:\n",
        "    assert x.is_cuda\n",
        "\n",
        "    n_rows, n_cols = x.shape\n",
        "    y = torch.empty_like(x)\n",
        "    grid = ceil(n_rows / block_size),\n",
        "    BLOCK_SIZE = triton.next_power_of_2(n_cols)  # Used to tile the row\n",
        "\n",
        "    fused_softmax_kernel[grid](x, y, x.stride(0), y.stride(0), n_rows, n_cols, BLOCK_SIZE)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "941a1e0d",
      "metadata": {
        "id": "941a1e0d",
        "outputId": "7343d5f0-0f9f-4546-ec00-1e533ff9150d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0428, 0.0593, 0.0543, 0.0390, 0.0805, 0.0934, 0.0425, 0.0617, 0.0456,\n",
            "         0.0625, 0.0457, 0.0873, 0.0536, 0.1016, 0.0796, 0.0507],\n",
            "        [0.0373, 0.0662, 0.0768, 0.0648, 0.0401, 0.0830, 0.0595, 0.0485, 0.0743,\n",
            "         0.0403, 0.0648, 0.0835, 0.0578, 0.0635, 0.0639, 0.0756],\n",
            "        [0.0690, 0.0838, 0.0886, 0.0692, 0.0522, 0.0561, 0.0501, 0.0531, 0.0724,\n",
            "         0.0529, 0.0493, 0.0611, 0.0696, 0.0464, 0.0630, 0.0634],\n",
            "        [0.0358, 0.0417, 0.0766, 0.0613, 0.0903, 0.0744, 0.0598, 0.0830, 0.0815,\n",
            "         0.0489, 0.0381, 0.0759, 0.0710, 0.0602, 0.0438, 0.0579],\n",
            "        [0.0563, 0.0745, 0.0683, 0.0878, 0.0602, 0.0612, 0.0491, 0.0928, 0.0869,\n",
            "         0.0430, 0.0741, 0.0445, 0.0470, 0.0560, 0.0427, 0.0558],\n",
            "        [0.0591, 0.0365, 0.0557, 0.0573, 0.0466, 0.0552, 0.0730, 0.0765, 0.0816,\n",
            "         0.0854, 0.0600, 0.0621, 0.0599, 0.0375, 0.0875, 0.0661],\n",
            "        [0.0584, 0.0595, 0.0545, 0.0773, 0.0755, 0.0902, 0.0878, 0.0412, 0.0646,\n",
            "         0.0822, 0.0712, 0.0410, 0.0435, 0.0546, 0.0532, 0.0454],\n",
            "        [0.0589, 0.0982, 0.0456, 0.0736, 0.0455, 0.0404, 0.0532, 0.0526, 0.0497,\n",
            "         0.0906, 0.0516, 0.0887, 0.0634, 0.0781, 0.0488, 0.0609]],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0428, 0.0593, 0.0543, 0.0390, 0.0805, 0.0934, 0.0425, 0.0617, 0.0456,\n",
            "         0.0625, 0.0457, 0.0873, 0.0536, 0.1016, 0.0796, 0.0507],\n",
            "        [0.0373, 0.0662, 0.0768, 0.0648, 0.0401, 0.0830, 0.0595, 0.0485, 0.0743,\n",
            "         0.0403, 0.0648, 0.0835, 0.0578, 0.0635, 0.0639, 0.0756],\n",
            "        [0.0690, 0.0838, 0.0886, 0.0692, 0.0522, 0.0561, 0.0501, 0.0531, 0.0724,\n",
            "         0.0529, 0.0493, 0.0611, 0.0696, 0.0464, 0.0630, 0.0634],\n",
            "        [0.0358, 0.0417, 0.0766, 0.0613, 0.0903, 0.0744, 0.0598, 0.0830, 0.0815,\n",
            "         0.0489, 0.0381, 0.0759, 0.0710, 0.0602, 0.0438, 0.0579],\n",
            "        [0.0563, 0.0745, 0.0683, 0.0878, 0.0602, 0.0612, 0.0491, 0.0928, 0.0869,\n",
            "         0.0430, 0.0741, 0.0445, 0.0470, 0.0560, 0.0427, 0.0558],\n",
            "        [0.0591, 0.0365, 0.0557, 0.0573, 0.0466, 0.0552, 0.0730, 0.0765, 0.0816,\n",
            "         0.0854, 0.0600, 0.0621, 0.0599, 0.0375, 0.0875, 0.0661],\n",
            "        [0.0584, 0.0595, 0.0545, 0.0773, 0.0755, 0.0902, 0.0878, 0.0412, 0.0646,\n",
            "         0.0822, 0.0712, 0.0410, 0.0435, 0.0546, 0.0532, 0.0454],\n",
            "        [0.0589, 0.0982, 0.0456, 0.0736, 0.0455, 0.0404, 0.0532, 0.0526, 0.0497,\n",
            "         0.0906, 0.0516, 0.0887, 0.0634, 0.0781, 0.0488, 0.0609]],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0428, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       device='cuda:0')\n",
            "(tensor(0.0428, device='cuda:0'), tensor(0., device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(8, 16).to(DEVICE)\n",
        "print(naive_softmax(x))\n",
        "print(fused_softmax_triton(x))\n",
        "torch.allclose(naive_softmax(x), fused_softmax_triton(x))\n",
        "print((naive_softmax(x) - fused_softmax_triton(x)))\n",
        "print((naive_softmax(x)[0,0], fused_softmax_triton(x)[0,0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9a57a9",
      "metadata": {
        "id": "5b9a57a9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}