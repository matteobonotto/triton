{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "YlFBDzu-LL6v",
      "metadata": {
        "id": "YlFBDzu-LL6v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from math import ceil\n",
        "from torch.autograd import Function\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "649083dd",
      "metadata": {
        "id": "649083dd"
      },
      "outputs": [],
      "source": [
        "import triton\n",
        "import triton.language as tl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "hRyr14v0wSwN",
      "metadata": {
        "id": "hRyr14v0wSwN"
      },
      "outputs": [],
      "source": [
        "def naive_softmax(x:Tensor) -> Tensor:\n",
        "    max = x.max()\n",
        "    x -= x.max(dim = -1)[0][:, None] # this is done for numerical stability\n",
        "    num = torch.exp(x)\n",
        "    den = torch.sum(num, dim=1)[:, None]\n",
        "    return num / den\n",
        "\n",
        "# x = torch.rand(100, 200).to(DEVICE)\n",
        "# triton.testing.assert_close(naive_softmax(x), torch.nn.functional.softmax(x, dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9JmqnyDWw3i4",
      "metadata": {
        "id": "9JmqnyDWw3i4"
      },
      "outputs": [],
      "source": [
        "@triton.jit\n",
        "def fused_softmax_kernel(x_pointer, y_pointer, x_stride, y_stride, n_rows, n_cols, block_size: tl.constexpr):\n",
        "    # get the program id: each program of the grid handles one (or more) rows of the tensor\n",
        "    pid = tl.program_id(axis=0)\n",
        "\n",
        "    # strided execution: can run the program in a strided way (e.g. for row 0, 8, 16, ...)\n",
        "    row_step = tl.num_programs(axis=0) # n. of programs running on given axis\n",
        "\n",
        "    # loop through the rows executed by program with this pid\n",
        "    for row_idx in tl.range(pid, n_rows, row_step):\n",
        "        x_row_pointer = x_pointer + row_idx * x_stride\n",
        "\n",
        "        col_offset = tl.arange(0, block_size)\n",
        "        x_col_pointer = x_row_pointer + col_offset\n",
        "        mask = n_cols < block_size\n",
        "\n",
        "        # compute the softmax (with shift for numerical stab.)\n",
        "        row = tl.load(x_col_pointer, mask, other=-float('inf'))\n",
        "\n",
        "        max = tl.max(row, axis=0)\n",
        "        row_shift = row - max\n",
        "\n",
        "        num = tl.exp(row_shift)\n",
        "        den = tl.sum(num, axis=0)\n",
        "        y = num / den\n",
        "\n",
        "        y_row_pointer = y_pointer + row_idx * y_stride\n",
        "        y_col_offset = y_row_pointer + col_offset\n",
        "        tl.store(y_col_offset, y, mask)\n",
        "\n",
        "\n",
        "def fused_softmax_triton(x:Tensor, block_size:int=1024) -> Tensor:\n",
        "    assert x.is_cuda\n",
        "\n",
        "    n_rows, n_cols = x.shape\n",
        "    y = torch.empty_like(x)\n",
        "    grid = ceil(n_rows / block_size),\n",
        "    BLOCK_SIZE = triton.next_power_of_2(n_cols)  # Used to tile the row\n",
        "\n",
        "    fused_softmax_kernel[grid](x, y, x.stride(0), y.stride(0), n_rows, n_cols, BLOCK_SIZE)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "941a1e0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "941a1e0d",
        "outputId": "e9529bb2-d54e-4800-fe86-3221156effe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor(0.0942, device='cuda:0'), tensor(0.9908, device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(8, 16).to(DEVICE)\n",
        "# print(naive_softmax(x))\n",
        "# print(fused_softmax_triton(x))\n",
        "# torch.allclose(naive_softmax(x), fused_softmax_triton(x))\n",
        "# print((naive_softmax(x) - fused_softmax_triton(x)))\n",
        "print((naive_softmax(x)[0,0], fused_softmax_triton(x)[0,0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "5b9a57a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9a57a9",
        "outputId": "53db5e2f-9a42-4e21-a03c-4a91512746b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0942, 0.0576, 0.0905, 0.0420, 0.0682, 0.0375, 0.0534, 0.0587, 0.0899,\n",
            "         0.0518, 0.0820, 0.0586, 0.0553, 0.0363, 0.0866, 0.0375],\n",
            "        [0.0777, 0.0814, 0.0803, 0.0514, 0.0616, 0.0827, 0.0537, 0.0421, 0.0649,\n",
            "         0.0782, 0.0569, 0.0477, 0.0480, 0.0680, 0.0559, 0.0495],\n",
            "        [0.0383, 0.0878, 0.0644, 0.0642, 0.0370, 0.0480, 0.0630, 0.0936, 0.0647,\n",
            "         0.0486, 0.0428, 0.0714, 0.0444, 0.0764, 0.0898, 0.0657],\n",
            "        [0.0700, 0.0701, 0.0549, 0.0801, 0.0880, 0.0803, 0.0426, 0.0735, 0.0394,\n",
            "         0.0735, 0.0372, 0.0427, 0.0469, 0.0712, 0.0503, 0.0791],\n",
            "        [0.0453, 0.0886, 0.0429, 0.0579, 0.0941, 0.0549, 0.0694, 0.0471, 0.0582,\n",
            "         0.0747, 0.0542, 0.0631, 0.0714, 0.0925, 0.0494, 0.0363],\n",
            "        [0.0411, 0.0372, 0.0799, 0.0953, 0.0631, 0.0579, 0.0665, 0.0808, 0.0661,\n",
            "         0.0374, 0.0369, 0.0571, 0.0450, 0.0654, 0.0804, 0.0899],\n",
            "        [0.0931, 0.0446, 0.0550, 0.0430, 0.0585, 0.0821, 0.0819, 0.0491, 0.0851,\n",
            "         0.0445, 0.0677, 0.0673, 0.0526, 0.0572, 0.0734, 0.0448],\n",
            "        [0.0709, 0.0549, 0.0387, 0.0681, 0.0862, 0.0655, 0.0379, 0.0498, 0.0433,\n",
            "         0.0998, 0.0620, 0.0575, 0.0469, 0.0838, 0.0562, 0.0785]],\n",
            "       device='cuda:0')\n",
            "tensor([[2.0000, 1.2701, 0.0905, 0.0420, 0.0682, 0.0375, 0.0534, 0.0587, 0.0899,\n",
            "         0.0518, 0.0820, 0.0586, 0.0553, 0.0363, 0.0866, 0.0375],\n",
            "        [0.0777, 0.0814, 0.0803, 0.0514, 0.0616, 0.0827, 0.0537, 0.0421, 0.0649,\n",
            "         0.0782, 0.0569, 0.0477, 0.0480, 0.0680, 0.0559, 0.0495],\n",
            "        [0.0383, 0.0878, 0.0644, 0.0642, 0.0370, 0.0480, 0.0630, 0.0936, 0.0647,\n",
            "         0.0486, 0.0428, 0.0714, 0.0444, 0.0764, 0.0898, 0.0657],\n",
            "        [0.0700, 0.0701, 0.0549, 0.0801, 0.0880, 0.0803, 0.0426, 0.0735, 0.0394,\n",
            "         0.0735, 0.0372, 0.0427, 0.0469, 0.0712, 0.0503, 0.0791],\n",
            "        [0.0453, 0.0886, 0.0429, 0.0579, 0.0941, 0.0549, 0.0694, 0.0471, 0.0582,\n",
            "         0.0747, 0.0542, 0.0631, 0.0714, 0.0925, 0.0494, 0.0363],\n",
            "        [0.0411, 0.0372, 0.0799, 0.0953, 0.0631, 0.0579, 0.0665, 0.0808, 0.0661,\n",
            "         0.0374, 0.0369, 0.0571, 0.0450, 0.0654, 0.0804, 0.0899],\n",
            "        [0.0931, 0.0446, 0.0550, 0.0430, 0.0585, 0.0821, 0.0819, 0.0491, 0.0851,\n",
            "         0.0445, 0.0677, 0.0673, 0.0526, 0.0572, 0.0734, 0.0448],\n",
            "        [0.0709, 0.0549, 0.0387, 0.0681, 0.0862, 0.0655, 0.0379, 0.0498, 0.0433,\n",
            "         0.0998, 0.0620, 0.0575, 0.0469, 0.0838, 0.0562, 0.0785]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(naive_softmax(x.clone()))\n",
        "print(fused_softmax_triton(x.clone()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MGyOh0bIJL1"
      },
      "id": "2MGyOh0bIJL1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}