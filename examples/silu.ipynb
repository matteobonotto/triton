{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "YlFBDzu-LL6v",
      "metadata": {
        "id": "YlFBDzu-LL6v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor, nn\n",
        "from math import ceil\n",
        "from torch.autograd import Function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fb2488",
      "metadata": {
        "id": "07fb2488"
      },
      "source": [
        "```math\n",
        "silu(x) = x * \\sigma(x) = \\frac{x}{1+e^{-x}}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1987645d",
      "metadata": {
        "id": "1987645d"
      },
      "outputs": [],
      "source": [
        "def naive_silu(x:Tensor) -> Tensor:\n",
        "    sigma = 1 / (1 + torch.exp(-x))\n",
        "    return x * sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "tNv4E9KJNOGd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "tNv4E9KJNOGd",
        "outputId": "f8f0d2cd-479d-40c9-c03e-f3df309a9d6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax-performance:\n",
            "          N      Triton       Torch  Naive SiLU\n",
            "0     256.0  198.297155  199.738847   34.763779\n",
            "1     896.0  222.784333  222.558344   35.342444\n",
            "2    1536.0  223.142159  226.784969   35.535460\n",
            "3    2176.0  224.199578  228.083070   35.803001\n",
            "4    2816.0  225.344369  229.263853   35.792121\n",
            "5    3456.0  225.666776  229.677442   35.849403\n",
            "6    4096.0  225.898020  230.542043   35.892775\n",
            "7    4736.0  226.667673  230.746535   35.917672\n",
            "8    5376.0  226.953862  230.909103   35.944663\n",
            "9    6016.0  226.815876  231.381601   35.924768\n",
            "10   6656.0  227.010180  231.301246   35.986854\n",
            "11   7296.0  227.242555  231.552367   36.015214\n",
            "12   7936.0  227.367665  231.682990   31.378247\n",
            "13   8576.0  199.508566  231.396813   35.959919\n",
            "14   9216.0  227.293445  231.773750   36.176894\n",
            "15   9856.0  228.486157  232.470458   35.968881\n",
            "16  10496.0  227.646872  232.266179   36.027474\n",
            "17  11136.0  228.622866  232.790011   36.024432\n",
            "18  11776.0  227.846457  232.118018   36.020758\n",
            "19  12416.0  228.086617  233.229233   36.085584\n"
          ]
        }
      ],
      "source": [
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "DEVICE = torch.device('cuda')\n",
        "import math\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def silu_kernel_fwd(x_poiter, act_pointer, sigma_pointer, num_elements, block_size: tl.constexpr):\n",
        "\n",
        "    pid = tl.program_id(axis=0)\n",
        "    pointers = pid*block_size + tl.arange(0, block_size)\n",
        "    mask = pointers < num_elements\n",
        "\n",
        "    x = tl.load(x_poiter+pointers, mask)\n",
        "    # sigma = 1 / (1 + tl.exp(-x))\n",
        "    # chunk_res = x * sigma\n",
        "    chunk_res = x / (1 + tl.exp(-x))\n",
        "\n",
        "    tl.store(act_pointer+pointers, chunk_res, mask)\n",
        "    # tl.store(sigma_pointer+pointers, sigma, mask)\n",
        "\n",
        "\n",
        "def silu_triton_fwd(x:Tensor, block_size:int=2048) -> Tensor:\n",
        "\n",
        "    num_elements = x.numel()\n",
        "    grid = ceil(num_elements / block_size),\n",
        "\n",
        "    act = torch.empty_like(x).to(x.device)\n",
        "    sigma = torch.empty_like(x).to(x.device)\n",
        "\n",
        "    silu_kernel_fwd[grid](x, act, sigma, num_elements, block_size)\n",
        "    return act#, sigma\n",
        "\n",
        "\n",
        "\n",
        "### performance\n",
        "x = torch.rand(100).to(DEVICE)\n",
        "triton.testing.assert_close(silu_triton_fwd(x), naive_silu(x))\n",
        "\n",
        "@triton.testing.perf_report(\n",
        "    triton.testing.Benchmark(\n",
        "        x_names=['N'],  # argument names to use as an x-axis for the plot\n",
        "        x_vals=[128 * i for i in range(2, 100, 5)],  # different possible values for `x_name`\n",
        "        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n",
        "        line_vals=['triton', 'torch', 'naive_silu'],  # possible values for `line_arg``\n",
        "        line_names=[\"Triton\", \"Torch\", \"Naive SiLU\"],  # label name for the lines\n",
        "        styles=[('blue', '-'), ('green', '-'), ('red', '-')],  # line styles\n",
        "        ylabel=\"GB/s\",  # label name for the y-axis\n",
        "        plot_name=\"softmax-performance\",  # name for the plot. Used also as a file name for saving the plot.\n",
        "        args={'M': 4096},  # values for function arguments not in `x_names` and `y_name`\n",
        "    ))\n",
        "def benchmark(M, N, provider):\n",
        "    x = torch.randn(M, N, device=DEVICE, dtype=torch.float32)\n",
        "    stream = getattr(torch, DEVICE.type).Stream()\n",
        "    getattr(torch, DEVICE.type).set_stream(stream)\n",
        "    if provider == 'torch':\n",
        "        ms = triton.testing.do_bench(lambda: torch.nn.functional.silu(x))\n",
        "    if provider == 'triton':\n",
        "        ms = triton.testing.do_bench(lambda: silu_triton_fwd(x))\n",
        "    if provider == 'naive_silu':\n",
        "        ms = triton.testing.do_bench(lambda: naive_silu(x))\n",
        "    gbps = lambda ms: 2 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
        "    return gbps(ms)\n",
        "\n",
        "\n",
        "benchmark.run(show_plots=True, print_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "dab69c20",
      "metadata": {
        "id": "dab69c20"
      },
      "outputs": [],
      "source": [
        "layer = nn.SiLU()\n",
        "\n",
        "class SiLUFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x:Tensor) -> Tensor:\n",
        "        sigma = 1 / (1 + torch.exp(-x))\n",
        "        ctx.save_for_backward(x, sigma)\n",
        "        return x * sigma\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x, sigma,  = ctx.saved_tensors\n",
        "        return grad_output * sigma * (1 + x * (1 - sigma))\n",
        "\n",
        "class SiLUFunctionCustomModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        in_shape = x.shape\n",
        "        return SiLUFunction.apply(x.view(x.numel())).view(in_shape)\n",
        "\n",
        "silu_custom = SiLUFunctionCustomModule()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4c4b0620",
      "metadata": {
        "id": "4c4b0620",
        "outputId": "6f904556-28e8-44a6-fad9-f153456001a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient 0: max diff = 1.1920928955078125e-07\n",
            "Gradient 1: max diff = 5.960464477539063e-08\n",
            "Gradient 2: max diff = 5.960464477539063e-08\n",
            "Gradient 3: max diff = 1.1920928955078125e-07\n",
            "Gradient 4: max diff = 1.1920928955078125e-07\n",
            "Gradient 5: max diff = 2.384185791015625e-07\n",
            "Gradient 6: max diff = 2.9802322387695312e-08\n",
            "Gradient 7: max diff = 5.960464477539063e-08\n"
          ]
        }
      ],
      "source": [
        "### Check forward pass\n",
        "x = torch.rand(8, 16, requires_grad=True)\n",
        "assert torch.allclose(naive_silu(x), SiLUFunction.apply(x))\n",
        "\n",
        "\n",
        "### Check backward pass\n",
        "x = torch.rand(8, 16, requires_grad=True)\n",
        "\n",
        "# Forward pass\n",
        "out_a = silu_custom(x)\n",
        "out_b = naive_silu(x)\n",
        "\n",
        "grad_output = torch.randn_like(out_a)\n",
        "\n",
        "# Backward pass A\n",
        "grads_a, = torch.autograd.grad(out_a, (x), grad_outputs=grad_output, retain_graph=True)\n",
        "\n",
        "# Backward pass B\n",
        "grads_b, = torch.autograd.grad(out_b, (x), grad_outputs=grad_output, retain_graph=True)\n",
        "\n",
        "for i, (ga, gb) in enumerate(zip(grads_a, grads_b)):\n",
        "    max_diff = (ga - gb).abs().max().item()\n",
        "    print(f\"Gradient {i}: max diff = {max_diff}\")\n",
        "    assert torch.allclose(ga, gb, atol=1e-6), f\"Mismatch in grad {i}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "bf3818bb",
      "metadata": {
        "id": "bf3818bb"
      },
      "outputs": [],
      "source": [
        "\n",
        "@triton.jit\n",
        "def silu_kernel_fwd(x_poiter, act_pointer, sigma_pointer, num_elements, block_size: tl.constexpr):\n",
        "\n",
        "    pid = tl.program_id(axis=0)\n",
        "    pointers = pid*block_size + tl.arange(0, block_size)\n",
        "    mask = pointers < num_elements\n",
        "\n",
        "    x = tl.load(x_poiter+pointers, mask)\n",
        "    # sigma = 1 / (1 + tl.exp(-x))\n",
        "    # chunk_res = x * sigma\n",
        "    chunk_res = x / (1 + tl.exp(-x))\n",
        "\n",
        "    tl.store(act_pointer+pointers, chunk_res, mask)\n",
        "    # tl.store(sigma_pointer+pointers, sigma, mask)\n",
        "\n",
        "\n",
        "def silu_triton_fwd(x:Tensor, block_size:int=2048) -> Tensor:\n",
        "\n",
        "    num_elements = x.numel()\n",
        "    grid = ceil(num_elements / block_size),\n",
        "\n",
        "    act = torch.empty_like(x).to(x.device)\n",
        "    sigma = torch.empty_like(x).to(x.device)\n",
        "\n",
        "    silu_kernel_fwd[grid](x, act, sigma, num_elements, block_size)\n",
        "    return act#, sigma\n",
        "\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def silu_kernel_bwd(\n",
        "    x_pointer,\n",
        "    # sigma_pointer,\n",
        "    grad_output_pointer,\n",
        "    dL_pointer,\n",
        "    num_elements,\n",
        "    block_size:tl.constexpr\n",
        "):\n",
        "    pid = tl.program_id(axis=0)\n",
        "\n",
        "    pointer_offset = pid*block_size + tl.arange(0, block_size)\n",
        "    mask = pointer_offset < num_elements\n",
        "\n",
        "    grad_output = tl.load(grad_output_pointer+pointer_offset, mask)\n",
        "    # sigma = tl.load(sigma_pointer+pointer_offset, mask)\n",
        "    x = tl.load(x_pointer+pointer_offset, mask)\n",
        "\n",
        "    sigma = 1 / (1 + tl.exp(-x))\n",
        "    dL = grad_output * sigma * (1 + x * (1 - sigma))\n",
        "    tl.store(dL_pointer+pointer_offset, dL, mask)\n",
        "\n",
        "\n",
        "def silu_triton_bwd(x:Tensor, grad_output:Tensor, block_size:int=2048) -> Tensor:\n",
        "    dL = torch.empty_like(grad_output)\n",
        "    num_elements = dL.numel()\n",
        "    grid = ceil(num_elements / block_size),\n",
        "    silu_kernel_bwd[grid](x, grad_output, dL, num_elements, block_size)\n",
        "    return dL\n",
        "\n",
        "\n",
        "class SiLUFunctionTriton(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x:Tensor) -> Tensor:\n",
        "        ctx.save_for_backward(x)\n",
        "        x = silu_triton_fwd(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\" dL = grad_output * sigma * (1 + x * (1 - sigma)) \"\"\"\n",
        "        x, = ctx.saved_tensors\n",
        "        dL = silu_triton_bwd(x, grad_output)\n",
        "        return dL\n",
        "\n",
        "class SiLUModuleTriton(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        in_shape = x.shape\n",
        "        return SiLUFunctionTriton.apply(x.view(x.numel())).view(in_shape)\n",
        "\n",
        "silu_fun_triton = SiLUFunctionTriton.apply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "6acf1d64",
      "metadata": {
        "id": "6acf1d64",
        "outputId": "8e5eec9b-7c34-47ff-a642-2276e49c0198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing mode: backward\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2624752481.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_plots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/testing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_plots, print_data, save_path, return_df, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbench\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mresult_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbench\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_plots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/testing.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, bench, save_path, show_plots, print_data, diff_col, save_precision, **kwrags)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mrow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_arg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwrags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0my_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2624752481.py\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(M, N, provider, mode)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_fwd_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mgbps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-9\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         ms, min_ms, max_ms = triton.testing.do_bench(\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/testing.py\u001b[0m in \u001b[0;36mdo_bench\u001b[0;34m(fn, warmup, rep, grad_to_none, quantiles, return_mode)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mdi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mdi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2624752481.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mgbps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-9\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         ms, min_ms, max_ms = triton.testing.do_bench(\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mgrad_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "### test that the results are correct\n",
        "# input tensor\n",
        "x = torch.rand(3, 4).to(DEVICE)\n",
        "dy = torch.randn_like(x)\n",
        "x.requires_grad = True\n",
        "\n",
        "# fwd pass\n",
        "act_torch = nn.functional.silu(x)\n",
        "act_triton = SiLUFunctionTriton.apply(x)\n",
        "\n",
        "# bkw pass (torch)\n",
        "act_triton.backward(dy, retain_graph=True)\n",
        "dx_triton  = x.grad.clone()\n",
        "x.grad = None\n",
        "\n",
        "# bwd pass (triton)\n",
        "act_torch.backward(dy, retain_graph=True)\n",
        "dx_torch  = x.grad.clone()\n",
        "\n",
        "# compare\n",
        "# print(dx_torch - dx_triton)\n",
        "# print((dx_torch - dx_triton).norm()/dx_torch.norm())\n",
        "assert torch.allclose(act_torch, act_triton, atol=1e-6, rtol=0)\n",
        "assert torch.allclose(dx_triton, dx_torch, atol=1e-6, rtol=0)\n",
        "\n",
        "\n",
        "\n",
        "### Compare performance\n",
        "@triton.testing.perf_report(\n",
        "    triton.testing.Benchmark(\n",
        "        x_names=['N'],\n",
        "        x_vals=[512 * i for i in range(2, 32)],\n",
        "        line_arg='provider',\n",
        "        line_vals=['triton', 'torch'] + (['apex'] if HAS_APEX else []),\n",
        "        line_names=['Triton', 'Torch'] + (['Apex'] if HAS_APEX else []),\n",
        "        styles=[('blue', '-'), ('green', '-'), ('orange', '-')],\n",
        "        ylabel='GB/s',\n",
        "        plot_name='layer-norm-backward',\n",
        "        args={'M': 4096, 'dtype': torch.float16, 'mode': 'backward'},\n",
        "    ))\n",
        "def bench_layer_norm(M, N, dtype, provider, mode='backward', eps=1e-5, device=DEVICE):\n",
        "    # create data\n",
        "    x_shape = (M, N)\n",
        "    w_shape = (x_shape[-1], )\n",
        "    weight = torch.rand(w_shape, dtype=dtype, device=device, requires_grad=True)\n",
        "    bias = torch.rand(w_shape, dtype=dtype, device=device, requires_grad=True)\n",
        "    x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device=device)\n",
        "    dy = .1 * torch.randn_like(x)\n",
        "    x.requires_grad_(True)\n",
        "    quantiles = [0.5, 0.2, 0.8]\n",
        "\n",
        "    def y_fwd():\n",
        "\n",
        "        if provider == \"triton\":\n",
        "            return silu_fun_triton(x, w_shape, weight, bias, eps)  # noqa: F811, E704\n",
        "\n",
        "        if provider == \"torch\":\n",
        "            return torch.nn.functional.silu(x, w_shape, weight, bias, eps)  # noqa: F811, E704\n",
        "\n",
        "    # forward pass\n",
        "    if mode == 'forward':\n",
        "        gbps = lambda ms: 2 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
        "        ms, min_ms, max_ms = triton.testing.do_bench(y_fwd, quantiles=quantiles, rep=500)\n",
        "    # backward pass\n",
        "    if mode == 'backward':\n",
        "        y = y_fwd()\n",
        "        gbps = lambda ms: 3 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)  # noqa: F811, E704\n",
        "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: y.backward(dy, retain_graph=True), quantiles=quantiles,\n",
        "                                                     grad_to_none=[x], rep=500)\n",
        "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
        "\n",
        "\n",
        "test_layer_norm(1151, 8192, torch.float16)\n",
        "bench_layer_norm.run(save_path='.', print_data=True)\n",
        "\n",
        "benchmark.run(show_plots=True, print_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6vuyH5tus5F"
      },
      "id": "j6vuyH5tus5F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQzioQtsszdE"
      },
      "id": "cQzioQtsszdE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIWhivbZpD_J"
      },
      "id": "aIWhivbZpD_J",
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}